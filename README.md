# Local RAG POC — Text + Chart Images (Cohere v4)

A minimal, local-first Retrieval-Augmented Generation (RAG) demo for PDFs and PowerPoint files.

It indexes:
- Text from PDFs and PPTX
- PDF page images (rasterized) with **captions** generated by OpenAI Vision (OCR fallback)
- Both text and captions are embedded with **Cohere Embed v4**

At query time it:
- Retrieves from text and captions using cosine similarity
- Fuses results via RRF, reranks with **local MMR** (no API needed), optional Cohere rerank fallback
- Generates a **quote-first answer** with inline `[file: page]` citations
- Runs a **vision verify** pass on selected page images to extract numeric/chart values

No database required. The index is stored as a single NPZ file in `.rag_cache/`.

---

## Features

- Local ingestion of PDFs and PPTX (text only for PPTX; page images for PDFs)
- OpenAI Vision captions for each PDF page (data URI upload-free); OCR fallback if OpenAI key is missing
- Cohere Embed v4 (text) for both document chunks and captions (normalized vectors)
- Dual-index retrieval (text + captions) with **RRF** fusion
- **Local MMR** reranking for diversity and precision (optional Cohere reranker if available)
- Quote-first answers with inline citations
- Vision verify pass on chosen image pages to read numbers/units from charts
- Single-file index (`.npz`) + cached page images under `.rag_cache/`

---

## Requirements

- Python 3.11+
- macOS, Linux, or Windows
- Optional: Tesseract OCR (improves fallback captions when OpenAI Vision is not used)
  - macOS: `brew install tesseract`
  - Ubuntu: `sudo apt-get install tesseract-ocr`

Python dependencies are in `requirements.txt`:
```
streamlit
numpy
pymupdf
python-pptx
openai
cohere
python-dotenv
pillow
pytesseract   # optional, only used if installed
```

---

## Quick start

### 1) Project layout
```
your-project/
├─ app.py
├─ requirements.txt
├─ .env
└─ docs/
   ├─ report.pdf
   └─ slides.pptx
```

### 2) Environment variables (`.env`)
```
COHERE_API_KEY=your_cohere_key
OPENAI_API_KEY=your_openai_key
```
- `OPENAI_API_KEY` is used for page captions and for answer generation (and vision-verify).  
- If `OPENAI_API_KEY` is missing, the app will:  
  - fall back to OCR-only captions (if Tesseract is installed)  
  - return a “quotes-only” answer (no LLM synthesis)

### 3) Install

Using **uv**:
```bash
uv python install 3.11
uv venv --python 3.11 .venv
uv pip install --python .venv/bin/python -r requirements.txt
```

Or with **pip**:
```bash
python -m venv .venv
source .venv/bin/activate         # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 4) Run
```bash
# uv
uv run --python .venv/bin/python streamlit run app.py

# or plain
streamlit run app.py
```

Open the URL printed by Streamlit (usually http://localhost:8501).

---

## Using the app

1. Place PDFs/PPTX under `./docs`.
2. In the sidebar, set the OpenAI model if needed (default: `gpt-4o-mini`).
3. Click **Build / Rebuild Index**. This will:
   - Parse text from PDFs and PPTX
   - Render PDF pages to PNGs
   - Caption images with OpenAI Vision (OCR fallback)
   - Embed text and captions with Cohere v4
   - Save a single `.npz` index in `.rag_cache/`
4. Ask a question in the main input box.
5. The app retrieves, fuses, reranks (local MMR by default), and generates a quote-first answer with citations.  
   If a chart is relevant, the app also performs a vision verify step and shows a short “chart value” bullet.

**Tunable retrieval controls:**
- **Retrieve K (before rerank):** how many top candidates are kept from each index (text and captions) before rerank.
  - Higher K → better recall but slightly more latency in rerank.
- **Context N (after rerank):** how many final chunks are passed to the LLM for the answer.
  - Higher N → broader context but more tokens/noise.
- **Reranker:** default is **local (MMR)**. Cohere-based rerank is optional and will auto-fallback to MMR if your account lacks access.

---

## How it works (pipeline)

1. **Ingestion**
   - **PDF text** via PyMuPDF (`get_text("text")`), chunked with a sentence window.
   - **PPTX text** via python-pptx (text frames, tables, notes).
   - **PDF page images** rasterized to PNG (180 dpi).

2. **Captioning**
   - OpenAI Vision generates a compact caption per page image (axes, units, series, trends, key numbers).
   - If the OpenAI key is missing or a caption fails, the system falls back to **OCR** (if installed).

3. **Embeddings**
   - **Cohere Embed v4** for both text chunks and image captions (normalized float32 vectors).
   - Stored in a single compressed **NPZ** alongside JSON metadata.

4. **Retrieval & Ranking**
   - Embed the query (`search_query`) and compute cosine similarities against both matrices.
   - **RRF fusion** merges text and caption results.
   - **MMR rerank** (local) promotes relevant yet diverse items. Optional Cohere rerank if available.

5. **Answering**
   - A quote-first OpenAI prompt extracts quotes and writes a synthesis with **inline `[file: page]` citations**.
   - **Vision verify** sends selected image pages to OpenAI Vision to read numeric values, appended as short bullets.

---

## Index and cache

- Index file: `.rag_cache/index_<hash>.npz`
  - Arrays: `text` (N×1024), `caps` (M×1024)
  - Metadata JSON blob: chunk fields (filepath, page, section, modality, etc.) and index mappings
- Page images: `.rag_cache/page_images/*.png`

To rebuild from scratch, delete `.rag_cache/` and click **Build / Rebuild Index** again.

---

## Troubleshooting

- **PyMuPDF not installed / import error**  
  Ensure `pymupdf` installed; on some platforms you may need system libraries or a clean venv.

- **OpenAI key missing**  
  - Captions: app falls back to OCR (requires Tesseract). If OCR is also missing, caption chunks will be empty and chart queries may be weaker.
  - Answers: app returns “quotes-only” output (no synthesis).

- **Cohere rerank 404 / model not found**  
  Use the default **local (MMR)** reranker. The “cohere (API)” option will automatically fall back to MMR if your account lacks access.

- **OCR quality poor**  
  Install Tesseract and ensure English language data is present; improve PDF quality or DPI in `render_pdf_pages_to_images` (default 180).

- **New documents not showing up**  
  Add them under `./docs`, then click **Build / Rebuild Index**.

- **Performance**  
  For larger corpora, increase K for better recall and adjust N to keep precision. If you outgrow brute-force retrieval, consider an ANN store (pgvector/Qdrant) later.

---

## Extending the POC

- **Metadata & filters:** add fields (tags, owners, dates) and filter before scoring.
- **ANN/vector DB:** swap `.npz` for pgvector or Qdrant for large-scale search.
- **PPTX images:** add slide rasterization if you need chart images from PPTX.
- **Faithfulness:** add a post-answer hallucination check or multi-hop decomposition.
- **UI:** show thumbnails in results list and allow clicking to open the source file/page.

---

## Security and privacy

- With `OPENAI_API_KEY` set, **page images and snippets** are sent to OpenAI for captioning, answer generation, and vision verify.
- If that is not acceptable for certain documents, run with OpenAI disabled (OCR-only captions, quotes-only answers) or isolate those documents.

---

## License

This demo is provided as-is for internal prototyping. Review third-party library licenses before production use.
